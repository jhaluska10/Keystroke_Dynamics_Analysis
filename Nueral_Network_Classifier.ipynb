{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jhaluska10/Keystroke_Dynamics_Analysis/blob/main/Nueral_Network_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import some of the important libraries to create a neural network using pytorch library"
      ],
      "metadata": {
        "id": "s_6SXNmtR6np"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2cKXvflb_d_e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35d06165-e012-4295-f493-ec05e3d79914"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.13)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2022.12.7)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.65.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.26.15)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4)\n",
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n",
            "keystroke-dynamics-challenge-1.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "Archive:  keystroke-dynamics-challenge-1.zip\n",
            "replace submit.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "import numpy as np  \n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import random\n",
        "\n",
        "!wget -q https://raw.githubusercontent.com/jhaluska10/kaggle/main/kaggle.json\n",
        "! pip install kaggle\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle competitions download  keystroke-dynamics-challenge-1\n",
        "! unzip  keystroke-dynamics-challenge-1.zip\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " \n",
        "Begin to parse the data for the neural network, creating press-press times, release-press times, release-release times, and hold durations. Also create the whole latency for each word (\"united\" and \"states\"). Finally, standardizes the inputs of the neural net."
      ],
      "metadata": {
        "id": "bmYdv1PrSGX7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "keystroke_info = pd.read_csv('train.csv')\n",
        "for i in range(13):\n",
        "  if(i != 0):\n",
        "    keystroke_info['PP-'+str(i)] = keystroke_info['press-'+str(i)] - keystroke_info['press-'+str(i-1)]\n",
        "    keystroke_info['RP-'+str(i)] = keystroke_info['release-'+str(i)] - keystroke_info['press-'+str(i-1)]\n",
        "    keystroke_info['RR-'+str(i)] = keystroke_info['release-'+str(i)] - keystroke_info['release-'+str(i-1)]\n",
        "  keystroke_info['HD-'+str(i)] = keystroke_info['release-'+str(i)] - keystroke_info['press-'+str(i)]\n",
        "\n",
        "#MAY WANT TO ADD DIGRAPHS laTER. AM UNSURE AS OF NOW'\n",
        "Latency_metric = ['HD', 'PP' , 'RR' , 'RP']\n",
        "#Latency_metric = [ 'PP' , 'RR' , 'RP']\n",
        "\n",
        "for val in Latency_metric:\n",
        "        lists = [col for col in keystroke_info.columns if val in str(col)]\n",
        "        #print(lists)\n",
        "        keystroke_info[str(val)+'-mean'] = keystroke_info[lists].mean(axis=1)\n",
        "        keystroke_info[str(val)+'-std'] = keystroke_info[lists].std(axis=1)\n",
        "\n",
        "for i in range(1,13):\n",
        "    keystroke_info['DG-'+str(i)] = keystroke_info['release-'+str(i)] - keystroke_info['press-'+str(i-1)]\n",
        "\n",
        "for i in range(2,13):\n",
        "    keystroke_info['TG-'+str(i)] = keystroke_info['release-'+str(i)] - keystroke_info['press-'+str(i-2)]\n",
        "keystroke_info[\"united_latency\"] =   keystroke_info['release-5'] - keystroke_info['press-0']\n",
        "keystroke_info[\"states_latency\"] =   keystroke_info['release-12'] - keystroke_info['press-7']\n",
        "keystroke_info\n",
        "results = keystroke_info[\"user\"]\n",
        "\n",
        "results_tensor = [[] for _ in results]\n",
        "for i in range(110):\n",
        "  for j in range(len(results_tensor)):\n",
        "    if j // 8 == i:\n",
        "      results_tensor[j].append(1)\n",
        "    else:\n",
        "      results_tensor[j].append(0)\n",
        "results_tensor = torch.Tensor(results_tensor)\n",
        "keystroke_info = keystroke_info.iloc[:,1:]\n",
        "inputs = nn.functional.normalize(torch.tensor(keystroke_info.values).float())\n",
        "\n",
        "#bins\n",
        "#normalize, batching, after optimizer.step see the weights, is it changing at all"
      ],
      "metadata": {
        "id": "wcoOPpUg8vKh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create the activation function as well as the structure of the neural net that attempts to categorize keystroke entries for each possible user. This neural net uses the Adam optimizer and a leaky ReLU activation function. The drawbacks of this method are that it could be difficult to add a new user into this neural net structure. "
      ],
      "metadata": {
        "id": "j9h_li4USNtC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "active = nn.LeakyReLU(0.1)\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self,nhidden=100,nin=108):\n",
        "        super(Net, self).__init__()\n",
        "        self.nhidden = nhidden\n",
        "        self.nin = nin\n",
        "        hidden_nodes = []\n",
        "        for h in range(nhidden):\n",
        "            hidden_nodes.append(torch.nn.Parameter((torch.rand(self.nin+1,1)-.5)*2/torch.sqrt(torch.tensor(2)))) \n",
        "        self.hidden_nodes = nn.ParameterList(hidden_nodes)\n",
        "        self.output = nn.Linear(nhidden, 110, bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.cat((x,-torch.ones((x.shape[0],1))),axis=1)\n",
        "        ys = []\n",
        "        for h in self.hidden_nodes:\n",
        "            ys.append(torch.matmul(x,h))\n",
        "        y = torch.cat(ys,dim=1)\n",
        "        y = active(y) # end of the hidden layer forward step?\n",
        "        y = torch.softmax(self.output(y),dim=1)\n",
        "        return y\n",
        "        \n",
        "    def predict(self,x):\n",
        "        return torch.round(self.forward(x))"
      ],
      "metadata": {
        "id": "Rwg9107oRZro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code creates the instances of the above defined neural nets and tests their accuracy which is output at the bottom of the code cell."
      ],
      "metadata": {
        "id": "-FB8fchCSDUw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "net = Net()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "nepochs = 100\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.1)\n",
        "train_loss = []\n",
        "val_loss = []\n",
        "models = []\n",
        "labels = results_tensor.float()\n",
        "\n",
        "# print(labels.shape)\n",
        "\n",
        "for epoch in range(nepochs):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = net(inputs)\n",
        "    # print(outputs.shape)\n",
        "    loss = criterion(outputs.float(), labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    train_loss.append(float(loss.data.numpy()))\n",
        "    val_loss.append(float(criterion(net(inputs).float(),labels).data.numpy()))\n",
        "    #models.append(copy.deepcopy(net))\n",
        "    \n",
        "    if epoch % 10 == 0:\n",
        "      print(f'[{epoch}] loss:',loss.data.numpy())\n",
        "\n",
        "\n",
        "outputs = net(inputs)\n",
        "correct = 0\n",
        "for i in range(len(outputs)):\n",
        "  if i // 8 == torch.argmax(outputs[i]).item():\n",
        "    correct += 1\n",
        "print(\"Accuracy\")\n",
        "print(correct / len(outputs))\n",
        "  #print(str(i) + \": \" + str(torch.argmax(outputs[i]).item()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zaj_EkvSp6z",
        "outputId": "556754bc-1b05-48d2-c22a-d1fff69736e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0] loss: 4.7004833\n",
            "[10] loss: 4.6667137\n",
            "[20] loss: 4.669607\n",
            "[30] loss: 4.6667924\n",
            "[40] loss: 4.666878\n",
            "[50] loss: 4.661177\n",
            "[60] loss: 4.660081\n",
            "[70] loss: 4.6598024\n",
            "[80] loss: 4.659669\n",
            "[90] loss: 4.6595798\n",
            "Accuracy\n",
            "0.05454545454545454\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We implement binning of the data here and see if the resulting model performs better."
      ],
      "metadata": {
        "id": "yW0_enAKVblM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bins = 10\n",
        "for i in range(len(inputs)):\n",
        "  inputs[i] = torch.round(inputs[i]/(1/bins)) * (1/bins)\n",
        "inputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9b2gzO7cVaoh",
        "outputId": "5bd17036-74b1-4e6c-9f15-d3d2c6ed5ee6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.1000, 0.1000, 0.2000],\n",
              "        [0.0000, 0.0000, 0.0000,  ..., 0.1000, 0.1000, 0.1000],\n",
              "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.2000, 0.1000],\n",
              "        ...,\n",
              "        [0.0000, 0.0000, 0.0000,  ..., 0.1000, 0.2000, 0.1000],\n",
              "        [0.0000, 0.0000, 0.0000,  ..., 0.1000, 0.2000, 0.1000],\n",
              "        [0.0000, 0.0000, 0.0000,  ..., 0.1000, 0.2000, 0.1000]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "net = Net()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "nepochs = 100\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.1)\n",
        "train_loss = []\n",
        "val_loss = []\n",
        "models = []\n",
        "labels = results_tensor.float()\n",
        "\n",
        "# print(labels.shape)\n",
        "\n",
        "for epoch in range(nepochs):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = net(inputs)\n",
        "    # print(outputs.shape)\n",
        "    loss = criterion(outputs.float(), labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    train_loss.append(float(loss.data.numpy()))\n",
        "    val_loss.append(float(criterion(net(inputs).float(),labels).data.numpy()))\n",
        "    #models.append(copy.deepcopy(net))\n",
        "    \n",
        "    if epoch % 10 == 0:\n",
        "      print(f'[{epoch}] loss:',loss.data.numpy())\n",
        "\n",
        "\n",
        "outputs = net(inputs)\n",
        "correct = 0\n",
        "for i in range(len(outputs)):\n",
        "  if i // 8 == torch.argmax(outputs[i]).item():\n",
        "    correct += 1\n",
        "print(\"Accuracy\")\n",
        "print(correct / len(outputs))\n",
        "  #print(str(i) + \": \" + str(torch.argmax(outputs[i]).item()))"
      ],
      "metadata": {
        "id": "5lmZgMSVVoPu",
        "outputId": "c5ce65a7-e6d9-4c66-ba02-1d90c576f9e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0] loss: 4.7004657\n",
            "[10] loss: 4.617484\n",
            "[20] loss: 4.586951\n",
            "[30] loss: 4.557546\n",
            "[40] loss: 4.525624\n",
            "[50] loss: 4.5106916\n",
            "[60] loss: 4.504655\n",
            "[70] loss: 4.4966416\n",
            "[80] loss: 4.4941335\n",
            "[90] loss: 4.491232\n",
            "Accuracy\n",
            "0.22613636363636364\n"
          ]
        }
      ]
    }
  ]
}